# Java的坑 代码篇

[PDF文档](D:\StudentFile\java\Java高手-代码篇.pdf)

并发工具
----

## ConcurrentHashMap

### 会出现线程安全问题

原因: ConcurrentHashMap 只能保证提供的原子性读写操作(比如 putIfAbsent, computeIfAbsent, replace, compute) 是线程安全的

size , isEmpty , containsValue 等聚合方法, 在并发情况下可能会反映中间状态 只能作为参考, 不能用于流程控制

解决: 如果需要确保多个原子性操作整体线程安全, 需要自己加锁解决

### 没有发挥性能优势

* 仍然想HashMap那样加了锁的方式会影响性能优势
* 考虑使用 computeIfAbsent,  putIfAbsent, getOrDefault 等方法提升性能

```text
public V computeIfAbsent(K key,
                         Function<? super K,? extends V> mappingFunction)
如果指定的键尚未与值相关联，则尝试使用给定的映射函数计算其值，并将其输入到此映射中，除非null 。 整个方法调用是以原子方式执行的，因此每个键最多应用一次该函数。 在计算过程中可能会阻止其他线程对该映射进行的某些尝试更新操作，因此计算应该简单而简单，不得尝试更新此映射的任何其他映射。
Specified by:
computeIfAbsent在界面 ConcurrentMap<K,V>
Specified by:
computeIfAbsent在界面 Map<K,V>
参数
key - 指定值与之关联的键
mappingFunction - 计算值的函数
结果
与指定键相关联的当前（现有或计算）值，如果计算值为空，则为null
异常
NullPointerException - 如果指定的键或mappingFunction为空
IllegalStateException - 如果计算可检测地尝试对此地图的递归更新，否则将永远不会完成
RuntimeException - 或者如果mappingFunction这样做，则出错，在这种情况下，映射未建立
```

```text
public V putIfAbsent(K key,
                     V value)
如果指定的键尚未与值相关联，请将其与给定值相关联。 这相当于
   if (!map.containsKey(key)) return map.put(key, value); else return map.get(key);  
除了动作以原子方式执行。
Specified by:
putIfAbsent在接口 ConcurrentMap<K,V>
Specified by:
putIfAbsent在界面 Map<K,V>
参数
key - 要与其关联的指定值的键
value - 与指定键相关联的值
结果
与指定键相关联的上一个值，如果没有键的映射， null
异常
NullPointerException - 如果指定的键或值为空
```

```text
public V getOrDefault(Object key,
                      V defaultValue)
返回指定键映射到的值，如果此映射不包含该键的映射，则返回给定的默认值。
Specified by:
getOrDefault中的 ConcurrentMap<K,V>
Specified by:
getOrDefault中的 Map<K,V>
参数
key - 要返回其关联值的键
defaultValue - 如果此映射不包含给定键的映射，则返回的值
结果
键的映射，如果存在; 否则为默认值
异常
NullPointerException - 如果指定的键为空
```

## CopyOnWriteArrayList

* 一个ArrayList的线程安全变体, 其中所有可变操作(add , set 等)通过对底层数据的最新副本实现
* 看了一下代码实现, 其底层数据的数组 就是 实际数据长度, 不像 ArrayList那样会有多余的空间
* 优点: 可以对CopyOnWrite容器进行并发的读, 而不需要加锁, 一种读写分离的思想, 读和写不同的容器  [文章](https://blog.csdn.net/u010002184/article/details/90452918)
* 场景: 白名单, 黑名单
* 缺点: 内存占用问题和数据一致性问题

### 在不合适的场景下使用, 导致的性能问题

原因: 每次修改复制一份数据

解决: 读多写少的场景才考虑 CopyOnWriteArrayList, 写多的场景考虑 ArrayList

代码加锁
----

* 没有识别线程安全问题的原因胡乱加锁
* 锁是实例级别的, 资源是类级别的, 无法有效保护
* 加锁颗粒度太大, 是的大段代码整体串行执行, 出现性能问题

## ReentrantLock [的使用](https://www.jianshu.com/p/155260c8af6c)

* 一个可重入互斥Lock具有与使用synchronized方法和语句访问的隐式监视锁相同的基本行为和语义, 但具有扩展功能

### 优点

* Java中已经有了内置锁: synchronized, 使用简单, 一切交给JVM去处理, 不需要显式释放
* 从用法上看比synchronized复杂, 必须在finally中进行解锁操作, 否则可能出现异常后锁没被释放
* 1.5时ReentrantLock的性能优于synchronized, 1.6时synchronized优化后, 性能区别不大了
* ReentrantLock 不是一种替代内置加锁的方法, 而是作为一种可选择的高级功能
* ReentrantLock 功能上更加丰富, 可重入, 可中断, 可限时, 公平锁

#### 可重入,  synchronized也可以

重入锁, 可以反复得到相同的一把锁, 他有一个与锁相关的获取计数器, 如果拥有锁的某个线程再次得到锁, 那么获取计数器就加1, 然后锁需要被释放两次才能获得真正的释放

```java
lock.lock();
lock.lock();
try{
    i++;
}finally{
    lock.unlock();
    lock.unlock();
}
```

#### 可中断

ReentrantLock对终端是有响应的, synchronized一旦尝试获取锁就是一直等待, 知道获取到锁

```java
import java.lang.management.ManagementFactory;
import java.lang.management.ThreadInfo;
import java.lang.management.ThreadMXBean;
import java.util.concurrent.locks.ReentrantLock;

import org.junit.Test;

public class ReentrantLockTest {

    @Test
    public void test() {
        try {
            LockInterrupt t1 = new LockInterrupt(1, "LockInterrupt1");
            LockInterrupt t2 = new LockInterrupt(2, "LockInterrupt2");
            t1.start();
            t2.start();
            Thread.sleep(1000);

            LockInterrupt.DeadlockChecker.check();

            Thread.sleep(10000);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public static class LockInterrupt extends Thread {

        public static ReentrantLock lock1 = new ReentrantLock();
        public static ReentrantLock lock2 = new ReentrantLock();

        int lock;

        public LockInterrupt(int lock, String name) {
            super(name);
            this.lock = lock;
        }

        @Override
        public void run() {
            System.out.println(Thread.currentThread().getId() + ":线程开始");
            try {
                if (lock == 1) {
                    lock1.lockInterruptibly();
                    try {
                        Thread.sleep(500);
                    } catch (Exception e) {
                    }
                    lock2.lockInterruptibly();
                } else {
                    lock2.lockInterruptibly();
                    try {
                        Thread.sleep(500);
                    } catch (Exception e) {
                    }
                    lock1.lockInterruptibly();
                }
            } catch (Exception e) {
            } finally {
                if (lock1.isHeldByCurrentThread()) {
                    lock1.unlock();
                }
                if (lock2.isHeldByCurrentThread()) {
                    lock2.unlock();
                }
                System.out.println(Thread.currentThread().getId() + ":线程退出");
            }
        }


        /**
         * 这里就是中断, 解决死锁
         */
        static class DeadlockChecker {
            private final static ThreadMXBean mbean = ManagementFactory.getThreadMXBean();

            public static void check() {
                Thread tt = new Thread(() -> {
                    {
                        while (true) {
                            long[] deadlockedThreadIds = mbean.findDeadlockedThreads();
                            if (deadlockedThreadIds != null) {
                                ThreadInfo[] threadInfos = mbean.getThreadInfo(deadlockedThreadIds);
                                for (Thread t : Thread.getAllStackTraces().keySet()) {
                                    for (int i = 0; i < threadInfos.length; i++) {
                                        if (t.getId() == threadInfos[i].getThreadId()) {
                                            System.out.println(t.getName());
                                            t.interrupt();
                                        }
                                    }
                                }
                            }
                            try {
                                Thread.sleep(5000);
                            } catch (Exception e) {
                            }
                        }
                    }
                });
                tt.setDaemon(true);
                tt.start();
            }
        }
    }
}

```

#### 可限时

* 超时不能获得锁, 就返回false, 不会永久等待构成死锁
* 使用 lock.tryLock(long timeout, TimeUnit unit) 来实现可限时锁, 参数为时间和单位

```java
@Test
    public void test2() {
        try {
            TryLockTest t1 = new TryLockTest("NAME 11");
            TryLockTest t2 = new TryLockTest("NAME 22");

            t1.start();
            t2.start();

            Thread.sleep(10000);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public static class TryLockTest extends Thread {
        private static ReentrantLock lock = new ReentrantLock();

        public TryLockTest(String name) {
            super(name);
        }

        @Override
        public void run() {
            try {
                if (lock.tryLock(5, TimeUnit.SECONDS)) {
                    Thread.sleep(6000);
                } else {
                    System.out.println(this.getName() + " get lock failed");
                }
            } catch (Exception e) {
            } finally {
                if (lock.isHeldByCurrentThread()) {
                    System.out.println("lock.isHeldByCurrentThread: " + this.getName());
                    lock.unlock();
                }
            }
        }
    }
```

#### 公平锁

* 一般意义上的锁是不公平的, 不一定先来的线程能先得到锁, 后来的线程就后得到锁, 不公平的锁可能会产生饥饿现象
* 公平锁的意思就是, 这个锁能保证线程是先来的先得到锁. 虽然公平锁不会产生饥饿现象, 但是公平锁的性能会比非公平锁差很多.

使用方法: 创建锁时, 传入true.  

```java
/** 构造函数 */
public ReentrantLock(boolean fair)

public static ReentrantLock fairLock = new ReentrantLock(true);
```

测试结果呢, 并不是线程1先启动, 就一定线程1拿到锁......

## 加锁没有考虑锁的场景, 可能导致性能问题

* 原因: 千篇一律使用写锁, 可以根据场景更细化地使用高级锁
* 解决1: 考虑使用 StampedLock 的乐观读的特性, 进一步提高性能
* 解决2: 对于读写比例差异明显的场景, 使用 ReentrantReadWriteLock细化区分读写锁
* 解决3: 在没有明确需求的情况下, 不要轻易开启公平锁特性

## StampedLock 是啥

* java1.8引入了一个新锁 StampedLock, 可被认为是 ReadWriteLock的改进
* ReadWriteLock中 读和写是互斥的, 如果一个线程在写共享变量的话, 其他线程读共享变量都会阻塞
* StampedLock把读分为 悲观读 和 乐观读, 悲观读等价于 ReadWriteLock的读, 而乐观读在一个线程写共享变量时, 不会被堵塞, 乐观锁是不加锁的. 性能比加锁摇号

```java
public class Point {
        private double x, y;
        private final StampedLock s1 = new StampedLock();

        // an exclusively locked method
        void move(double deltaX, double deltaY) {
            // 获得写锁
            long stamp = s1.writeLock();
            try {
                x += deltaX;
                y += deltaY;
            } finally {
                // 释放写锁
                s1.unlockWrite(stamp);
            }
        }

        // A read-only method
        double distanceFromOrigin() {
            // 乐观锁
            long stamp = s1.tryOptimisticRead();
            double currentX = x, currentY = y;
            // 判断共享变量是否已经被其他线程写过
            if (!s1.validate(stamp)) {
                // 如果被写过则升级为悲观读锁
                stamp = s1.readLock();
                try {
                    currentX = x;
                    currentY = y;
                } finally {
                    // 释放悲观读锁
                    s1.unlockRead(stamp);
                }
            }
            return Math.sqrt(currentX * currentX + currentY * currentY);
        }

        // 升级
        void moveIfAtOrigin(double newX, double newY) {
            // could instead start with optimistic, not read mode
            // 获取读锁
            long stamp = s1.readLock();
            try {
                while (x == 0.0 && y == 0.0) {
                    // 升级为写锁
                    long ws = s1.tryConvertToWriteLock(stamp);
                    if (ws != 0L) {
                        stamp = ws;
                        x = newX;
                        y = newY;
                        break;
                    } else {
                        s1.unlockRead(stamp);
                        stamp = s1.writeLock();
                    }
                }
            } finally {
                s1.unlock(stamp);
            }
        }

    }
```

* 如果有写操作改变了共享变量, 则升级乐观读为悲观读锁, 这样避免乐观读反复的循环等待写锁的释放, 避免浪费CPU资源.

* StampedLock不是可重入锁, 所以不支持重入, 并且StampedLock不支持条件变量, 也就是没有Condition. 如果是线程使用writeLock()或者readLock()获得锁之后, 线程还没执行完就被interrupt()的话, 会导致CPU飙升.

* 所以要使用中断功能就得用 readLockInterruptibly() 或者 writeLockInterruptibly()来获得锁

#### ReentrantReadWriteLock [用法](https://www.jianshu.com/p/4b45f9a1f7d2)

* ReentrantLock 是互斥排他锁, 同一时间只能有一个线程执行任务, 支持所得重入功能， 虽然确保了线程的安全性， 但是效率不高
* ReentrantReadWriteLock 读写互斥， 读操作贡献那个

* 读读共享
* 写写互斥
* 读写互斥

总结: 读操作的锁叫共享锁, 写操作的锁叫排它锁. 就是遇见写锁就需要互斥.

```java
import java.util.concurrent.locks.ReentrantReadWriteLock;

import org.junit.Test;

/**
 * ReentrantLockTest.java
 * 
 * @author thght
 * @version 2021年1月8日
 */
public class ReentrantReadWriteLockTest {

    /**
     * 读读共享
     */
    @Test
    public void testReadRead() {
        try {
            final LockTest lockTest = new LockTest();

            Thread t1 = new Thread(new Runnable() {

                @Override
                public void run() {
                    lockTest.read();

                }
            });
            t1.setName("t1");

            Thread t2 = new Thread(new Runnable() {

                @Override
                public void run() {
                    lockTest.read();

                }
            });
            t2.setName("t2");

            t1.start();
            t2.start();

            Thread.sleep(3000);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * 写写互斥
     */
    @Test
    public void testWriteWrite() {
        try {
            final LockTest lockTest = new LockTest();

            Thread t1 = new Thread(new Runnable() {

                @Override
                public void run() {
                    lockTest.write();

                }
            });
            t1.setName("t1");

            Thread t2 = new Thread(new Runnable() {

                @Override
                public void run() {
                    lockTest.write();

                }
            });
            t2.setName("t2");

            t1.start();
            t2.start();

            Thread.sleep(3000);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * 读写互斥
     */
    @Test
    public void testReadWrite() {
        try {
            final LockTest lockTest = new LockTest();

            Thread t1 = new Thread(new Runnable() {

                @Override
                public void run() {
                    lockTest.write();

                }
            });
            t1.setName("t1");

            Thread t2 = new Thread(new Runnable() {

                @Override
                public void run() {
                    lockTest.read();

                }
            });
            t2.setName("t2");

            t1.start();
            t2.start();

            Thread.sleep(3000);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * 可中断 功能案例
     * 
     * @author thght
     *
     */
    public static class LockTest {

        public ReentrantReadWriteLock lock = new ReentrantReadWriteLock();

        public void read() {
            try {
                lock.readLock().lock();
                System.out.println(Thread.currentThread().getName() + " read start");
                Thread.sleep(1000);
                System.out.println(Thread.currentThread().getName() + " read end");
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                lock.readLock().unlock();
            }
        }

        public void write() {
            try {
                lock.writeLock().lock();
                System.out.println(Thread.currentThread().getName() + " write start");
                Thread.sleep(1000);
                System.out.println(Thread.currentThread().getName() + " write end");
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                lock.writeLock().unlock();
            }
        }

    }
}

```

* 多把锁时, 要格外小心死锁问题
  * 原因: 多把锁相互等待对方释放, 导致死锁
  * 解决: 加锁的时候考虑顺序, 按顺序加锁不易死锁
  * 工具: 使用VisualVM的线程Dump, 查看死锁问题并分析死锁原因

线程池
-----

* 使用 Executors 声明线程池导致两种类型的 OOM(OutOfMemory内存溢出)
  * 原因1: newFixedThreadPool 使用无界队列, 队列堆积太多数据导致OOM
  * 原因2: newCachedThreadPool 不限制最大线程数并且使用没有任何容量的SynchronousQueue作为队列, 容易开启太多线程导致OOM
  * 解决: 手动 new ThreadPoolExecutor, 根据需求设置合适的核心线程数, 最大线程数, 线程回策略, 队列, 拒绝策略, 并对线程进行明确的命名以方便排查问题

### ThreadPoolTaskExecutor 和 ThreadPoolExecutor 区别

[文章](https://blog.csdn.net/weixin_43168010/article/details/97613895)

1. ThreadPoolExecutor

* 是JDK中的线程池类, 继承自Executor.
* Executor 是专门用来处理多线程相关的接口, 所有线程相关的类都实现了这个接口, execute()方法, 用来执行线程, 线程池主要提供一个线程队列, 队列中保存着所有等待状态的线程. 避免了创建与销毁的额外开销,提高了相应速度.

|                                |                       |                               |
| ------------------------------ | --------------------- | ----------------------------- |
|                                | 接口 Executor         |                               |
|                                | 继承↑                 |
|                                | 接口 ExecutorService  |
| 实现 ↗                         |                       | ↖ 继承                        |
| 抽象类 AbstractExecutorService |                       | 接口 ScheduledExecutorService |
| 继承 ↑                         | 继承↖                 | 实现↑                         |
| 类 ForkJoinPool                | 类 ThreadPoolExecutor | ↑                             |
|                                | 继承 ↖                | ↑                             |
|                                |                       | ScheduledThreadPoolExecutor   |

一. 线程池接口: ExecutorService

* 提供了线程池生命周期方法, 继承自Executor接口, ThreadPoolExecutor为线程池实现类, 提供了线程池的维护操作等相关方法, 继承自AbstractExecutorService, AbstractExecutorService实现了ExecutorService接口

三. 工具类: Executors

* 线程池工具类, 相当于一个工厂类, 用来创建合适的线程池, 返回ExecutorService类型的线程池
  * ExecutorService newFixedThreadPool(): 创建固定大小的线程池
  * ExecutorService newCachedThreadPool(): 缓存线程池, 线程池的数量不固定, 可以根据需求自动的更改数量
  * ExecutorService newSingleThreadExecutor(): 创建单个线程池, 线程池中只有一个线程
  * ScheduledExecutorService newScheduledThreadPool(): 创建固定大小的线程池, 可以延迟或定时的执行任务

2. ThreadPoolTaskExecutor

这个类是Spring包下的, 是Spring提供的线程池类

* 拒绝策略

rejectedExecutionHandler参数字段用于配置拒绝策略, 常用拒绝策略如下:用于被拒绝任务的处理程序

* AbortPolicy: 将抛出RejectedExecutionException
* CallerRunsPolicy: 直接在ececute方法的调用线程中运行被拒绝的任务
* DiscardOldestPolicy: 放弃最就的未处理请求, 然后重试execute
* DiscardPolicy: 默认情况下将丢弃被拒绝的任务

* 处理流程

1. 查看核心线程池是否已满, 不满就创建一条线程执行任务, 否则执行第二步
2. 查看任务列表是否已满, 不满就将任务存储在任务队列中, 否则执行第三步
3. 查看线程池是否已满, 即是否达到最大线程池数, 不满就创建一条线程执行任务, 佛足额就按照策略处理无法执行的任务

* 线程池线程管理策略详解: 如何实现一个更激进的线程池?
  * 原因: Java的线程池倾向于优先使用队列, 队列满了再开启更多线程
  * 解决: 重新队列的offer方法直接返回false, 数据不入队列, 并且自定义 RejectedExecutionHandler, 触发拒绝策略的时候, 再把任务加入队列; 参考 Tomcat 的 ThreadPoolExecutor 和 TaskQueue 类
  * Dubbo中 EagerThreadPoolExecutor 有类似Tomcat的实现

#### EagerThreadPoolExecutor

[文章](https://www.jianshu.com/p/8156ee310eb3?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)

* maximumPoolSize  是真的最大值, 包括了 核心线程数
* 同一时间最大处理能力 = maximumPoolSize + 任务队列尺寸

##### spring boot 中引入 dubbo的 Eager线程池

```xml
  <!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-common -->
  <dependency>
   <groupId>org.apache.dubbo</groupId>
   <artifactId>dubbo-common</artifactId>
   <version>2.7.8</version>
  </dependency>
```

``` java
// 一个可以继承父线程的 MDC
import java.util.concurrent.RejectedExecutionHandler;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;

import org.apache.dubbo.common.threadpool.support.eager.EagerThreadPoolExecutor;
import org.apache.dubbo.common.threadpool.support.eager.TaskQueue;
import org.springframework.core.task.TaskDecorator;
import org.springframework.lang.Nullable;

/**
 * MyEagerThreadPoolExecutor.java
 * @author thght
 * @version 2021年1月27日
 */
public class MyEagerThreadPoolExecutor extends EagerThreadPoolExecutor {

    @Nullable
    private TaskDecorator taskDecorator;

    public MyEagerThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,
            TaskQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) {
        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);
    }

    public void setTaskDecorator(TaskDecorator taskDecorator) {
        this.taskDecorator = taskDecorator;
    }

    @Override
    public void execute(Runnable command) {
        Runnable decorated = command;
        if (this.taskDecorator != null) {
            decorated = taskDecorator.decorate(command);
        }
        super.execute(decorated);
    }
}

import java.lang.reflect.Method;
import java.util.Map;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

import org.apache.dubbo.common.threadlocal.NamedInternalThreadFactory;
import org.apache.dubbo.common.threadpool.support.eager.TaskQueue;
import org.slf4j.MDC;
import org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.task.TaskDecorator;
import org.springframework.scheduling.annotation.AsyncConfigurer;

import cn.xxx.activitytermstarts.common.pool.MyEagerThreadPoolExecutor;
import lombok.extern.slf4j.Slf4j;

/**
 * 异步任务配置
 *
 * @author 作者: thght
 * @version 创建时间: 2018年7月9日
 */
@Configuration
@Slf4j
public class TaskExecutePool implements AsyncConfigurer {

    public static final int THREAD_NUM = 10;

    /** 线程池核心线程数 */
    private static final int CORE_POOL_SIZE = 10;
    /** 请求队列最大*/
    private static final int QUEUE_CAPACITY = 50;
    /** 线程池最大数 */
    public static final int MAX_POOL_SIZE = 80;

    @Override
    @Bean("taskExecutor1")
    public ThreadPoolExecutor getAsyncExecutor() {
        TaskQueue<Runnable> taskQueue = new TaskQueue<>(QUEUE_CAPACITY);
        MyEagerThreadPoolExecutor executor = new MyEagerThreadPoolExecutor(CORE_POOL_SIZE, MAX_POOL_SIZE, 60,
                TimeUnit.SECONDS, taskQueue, new NamedInternalThreadFactory("sub-q-", true),
                new ThreadPoolExecutor.CallerRunsPolicy());
        executor.setTaskDecorator(new MdcTaskDecorator());
        taskQueue.setExecutor(executor);
        log.info("线程池的配置: 最大{}, 最小{}, 队列最大{}", MAX_POOL_SIZE, CORE_POOL_SIZE, QUEUE_CAPACITY);
        return executor;
    }

    @Override
    public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
        return new TaskExecutePoolAsyncUncaughtExceptionHandler();
    }
}

/**
 * 异步任务中异常处理
 *
 * @author thght
 */
@Slf4j
class TaskExecutePoolAsyncUncaughtExceptionHandler implements AsyncUncaughtExceptionHandler {
    @Override
    public void handleUncaughtException(Throwable arg0, Method arg1, Object... arg2) {
        log.error("=========================={}=======================", arg0.getMessage(), arg0);
        log.error("exception method:{}", arg1.getName());
    }
}

/**
 * 让@Async注解可以获取到mdc中的内容<br/>
 * decorate()方法的参数是一个Runnable对象，返回结果也是另一个Runnable对象,这里，只是把原始的Runnable对象包装了一下，首先取得MDC数据，然后把它放到了委托的run方法里.
 */
class MdcTaskDecorator implements TaskDecorator {

    @Override
    public Runnable decorate(Runnable runnable) {
        try {
            // Right now: Web thread context !
            // Grab the current thread MDC data
            Map<String, String> copyOfContextMap = MDC.getCopyOfContextMap();

            return () -> {
                // Right now: @Async thread context !
                // Restore the Web thread context's MDC data
                MDC.setContextMap(copyOfContextMap);
                runnable.run();
            };
        } finally {
            //      MDC.clear();
        }
    }

}

```

* 没有复用线程池, 导致频繁创建线程的事故
  * 原因: 获取线程池的方法每次都返回一个 newCachedThreadPool, 好在 newCachedThreadPool 可以限制回收
  * 解决: 使用静态字段定义线程池, 线程池务必重用

* A12 混用线程池, 导致性能问题
  * 原因: IO绑定操作和CPU绑定操作混用一个线程池, 前者因为负担中, 线程长期处于忙的状态, 导致CPU操作吞吐收到影响
  * 解决: 根据任务的类型声明合适的线程池, 不同类型的任务考虑使用独立线程池
  * 扩展: Java 8 的ParallelStream背后是一个公共线程池, 别把IO任务使用 ParallelStream 来处理

#### ParallelStream介绍

[文档](https://www.jianshu.com/p/3d4e76467990)

* 并行流
* parallelStream()方法 或者 stream().parallel()
* java 的并行 API 延边流程
  * 1.0 - 1.4 中的 java.lang.Thread
  * 5.0 中的 java.util.concurrent
  * 6.0 中的 Phasers 等
  * 7.0 中的 Fork/Join 框架
  * 8.0 中的 Lambda

##### parallelStream 是什么?

* 是一个并行执行的流, 通过默认的ForkJoinPool, 可能提高的你的多线程任务的速度
* 多个parallelStream之间默认使用的是同一个线程池, 所以IO操作尽量不要放进parallelStream中, 否则会阻塞其他parallelStream.
* parallelStream 默认的并发线程数要比CPU处理器的数量少1个, 因为主线程要占用一个CPU

##### 从parallelStream 认识 Fork/Join 框架

* 核心思想:分治法, 讲一个大任务拆分为若干不依赖的子任务, 把这些子任务分别放到不同的队列, 并为每个队列创建一个单独的线程来执行队列里的任务.
* 为了最大限度地提高并发处理能力, 采用了 工作窃取算法来运行任务, 即 当某个线程处理完自己的工作队列中的任务后, 尝试从其他线程的工作队列中窃取一个任务来执行, 知道所有的任务处理完成. 所以为了减少线程之间的竞争, 通常会使用双端队列, 被企鹅去任务线程永远从队列的头部那任务执行. 而且去任务的线程永远从双端队列的尾部拿任务执行

##### 使用parallelStream的利弊

* 好处:
  * 代码优雅, 可以使用lambda表达式, 原本几句代码现在依据可以搞定(相比于其他并行方式)
  * 运用多喝特性(forkAndJoin)并行处理, 大幅提高效率
* 坏处:
  * 机器不便于代码的跟踪调试
  * 并行流带来的不确定性也使得对他的使用变得格外谨慎

* 使用时的注意点:
  * parallelStream是线程不安全的   解决方法: 加锁, 使用线程安全的集合 或者 采用 collect() 或者 reduce()
  * parallelStream 使用的场景是CPU密集型的, 只是做到别浪费CPU,
    * I/O密集型 磁盘I/O, 网络I/O 都属于I/O操作, 这部分操作是较少消耗CPU资源, 一般并行流中不适合于I/O密集型的操作, 比如使用并行流进行大量的消息推送, 设计到了大量I/O, 使用并姓刘反而慢了很多
    * CPU密集型 计算类型就属于CPU密集型, 这种操作并行流就能提高运行效率
  * 不要在多线程中使用parallelStream, 都抢着CPU是没有提升效果, 反而还会加大线程切换开销
  * 会带来不确定性, 请确保每条处理无状态且没有关联
  * 考虑NQ模型: N可用的数据量, Q针对每个数据元素执行的计算量, 乘积N*Q越大, 就越有可能获得并行提速,
  * parallelStream是创建一个并行的Stream. 并且它的并行操作是不具备线程传播性的, 所以是无法获取ThreadLocal创建的线程变量的值;
  * 在使用并行流的时候是无法保证元素的顺序的, 也就是几十你用了同步集合也只能保证元素都正确单无法保证其中的顺序
  * lambda的执行并不是瞬间完成的, 所以使用 parallelStream 的程序都有可能成为苏泽程序的源头, 并且在执行过程中程序中的其他部分将无法访问这些workers, 这意味着任何依赖parallelStream的程序在什么别的东西占用着 common ForkJoinPool是将会变得不可预知并且暗藏危机

并行 和 并发 的关系
并行是同时发生的多个并发事件, 在同一时刻利用CPU的多核, 让多个线程运行在多个CPU上, 因此并行比并发具有更高的CPU利用率, 侠侣相对更高, 并行具有并发的含义, 但并发不一定并行, 并发事件之间不一定要同一时刻发生.

* A13 CallerRunsPolicy 拒绝策略可能带来的问题
  * 原因: 如果设置 CallerRunsPolicy , 那么被拒绝的任务会由提交任务的线程运行, 可能会在线程池满载的情况下直接拖垮整个应用
  * 解决: 对于 Web 和 Netty 场景, 要仔细考虑把任务提交到线程池异步执行使用的拒绝策略, 除非有明确的需求, 否则不考虑使用CallerRunsPolicy拒绝策略

#### 拒绝策略场景分析

* AbortPolicy
  * 丢弃任务 并 抛出 RejectedExecutionException 异常
  * 默认的拒绝策略, 在任务不能提交的时候, 抛出异常, 及时反馈程序运行状态.
  * 如果是比较关键的业务, 推荐, 在系统不能承载更大的并发量的时候, 能及时通过异常发现
* DiscardPolicy
  * 丢弃任务, 但不会抛出异常. 静默丢弃
  * 无法发现系统的异常状态. 建议是一些无关紧要的业务采用此策略. 例如统计阅读量
* DiscardOldestPolicy
  * 丢弃队列最前面的任务, 然后重新提交被拒绝的任务
  * 根据实际业务, 新任务比老任务重要的情况, 比如: 发布消息
* CallerRunsPolicy
  * 由调用线程处理该任务
  * 如果任务被拒绝, 则由调用线程直接执行次任务,  不允许失败的场景, 对性能要求不高, 并发量较小

## 连接池

* A14  常见的 Client SDK 的API, 有哪三种形式?
  * 形式1: 内部带有连接池的API: SDK内部会先自动通过连接池获取连接 (几乎所有的数据库连接池都是这一类)
  * 形式2: 连接池和连接分离的API: 使用者先通过连接池获取连接, 在使用连接执行操作 (Jedis)
  * 形式3: 非连接池的API: 非线程安全, 需要使用者自己封装连接池
