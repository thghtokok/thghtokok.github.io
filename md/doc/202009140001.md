# Redis 开发与运维 读书笔记

## 第七章 Redis的噩梦：阻塞 P402

* 单线程架构，出现阻塞就是噩梦
* 阻塞的原因包括：
  * 内在原因包括：不合理地使用API或数据结构、CPU饱和、持久化阻塞等
  * 外在原因包括：CPU竞争、内存交换、网络问题等

### 7.1 发现阻塞

* Jedis 抛出 JedisConnectionException 
* 同一日志输出到Error日志中，标记报错的Redis节点，有效的报警
* 监控系统所监控的关键指标有很多，命令耗时、慢查询、持久化阻塞、连接拒绝、CPU/内存/网络/磁盘使用过载

### 7.2 内在原因

定位到具体的Redis节点异常后，首先应该排查是否是Redis自身原因导致

* 7.2.1 API或数据结构使用不合理

例如：由于数据量比较大且命令算法复杂度是O(n)

避免在高并发的场景是在大对象上执行算法复杂度超过O(n)

1. 如何发现慢查询

slowlog get{n} 命令可以获得最近的n条慢查询命令
调整慢查询：
   * 修改为低算法度的命令：hgetall 改为 hmget， 禁用keys、sort等命令
   * 调整大对象：缩减大对象数据或把大对象拆分为多个小对象，防止一次命令操作过多的数据

2. 如何发现大对象

redis-cli-h{ip}-p{port}bigkeys

* 7.2.2 CPU饱和的问题

CPU饱和指Redis把单核CPU使用率跑到接近100%，CPU饱和非常危险

先判断当前Redis的并发量是否达到极限，redis-cli-h{ip}-p{port}--stat获取当前Redis使用情况

如果接近饱和，垂直层面的命令优化无效，需要做集群化水平扩展来分担OPS压力
如果不饱和却CPU饱和，可能是使用了高算法复杂度的命令或过度的内存优化

* 7.2.3 持久化相关的阻塞

1. fork阻塞
2. AOF刷盘阻塞
3. HugePage写操作阻塞

### 7.3 外在原因

* 7.3.1 CPU竞争  P414

  * 进程竞争：Redis是典型CPU密集型应用，不建议和其它多核CPU密集型服务部署在一起。



## 第六章 复制 P351

### 6.5 重点回顾

1) Redis通过复制功能实现主节点的多个副本。从i二点可灵活地通过slaveof命令建立或断开复制流程
2) 复制支持树状结构，从节点可以复制另一个从节点，实现一层层向下的复制流。Redis2.8之后复制的流程分为全量复制和部分复制。
   1) 全量复制需要同步全部主节点的数据集，大量消耗机器和网络资源
   2) 部分复制有效减少因网络异常等原因造成的不必要全量复制情况
   3) 通过配置合理的复制积压缓冲区尽量避免全量复制。
3) 主从节点之间维护心跳和偏移量检查机制，保证主从节点通信正常和数据一致。
4) Redis为了保证高性能复制过程是异步的，写命令处理完后直接返回给客户端，不等待从节点复制完成。因此从节点数据集会有延迟情况
5) 当使用从节点用于读写分离时会存在数据延迟、过期数据、从节点可用性等问题，需要根据自身业务提前作出规避
6) 在运维过程中，主节点存在多个从节点或者一台机器上部署大量主节点的情况下，会有复制风暴的风险

## 第五章 持久化

### 5.5 重点回顾

* Redis提供了两种持久化方式：RDB 和 AOF
* RDB使用一次性生成内存快照的方式，产生的文件紧凑压缩比更高，因此读取RDB恢复速度更快。由于每次生成RDB开销较大，无法做到实施持久化，一般用于数据冷备和复制传输
* save命令会阻塞主线程不建议使用，bgsave命令通过fork操作创建子进程生成RDB避免阻塞
* AOF通过追加写命令到文件实现持久化，通过appendfsync参数可以控制实时/秒级持久化。因为需要不断追加写命令，所以AOF文件体积逐渐变大，需要定期执行重写操作来降低文件体积。
* AOF重写可以通过auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数控制自动触发，也可以使用bgrewriteaof命令手动触发。
* 子进程执行期间使用copy-on-write机制与父进程共享内存，避免内存消耗翻倍。AOF重写期间还需要维护重写缓存区，保存新的写入命令避免数据丢失。
* 持久化阻塞主线程场景有：fork阻塞和AOF追加阻塞。fork阻塞时间跟内存量和系统有关，AOF追加阻塞说明硬盘资源紧张。
* 单机下部署多个实例时，为了防止出现多个子进程执行重写操作，建议做隔离控制，避免CPU和IO资源竞争



## 第四章 客户端

### 4.7 重点回顾
1) RESP保证客户端与服务端的正常通信, 是各种编程语言开发客户端的基础
2) 要选择社区活跃客户端, 在实际项目中使用稳定版本的客户端
3) 区分Jedis直连和连接池的区别, 在生产环境中, 使用连接池
4) Jedis.close()在直连下是关闭连接, 在连接池则是归还连接
5) Jedis客户端没有内置序列换,需要自己选用
6) 客户端输入缓冲区不能配置, 强制限制在1G之内, 但是不会受到maxmemory限制
7) 客户端输出缓冲区支持普通客户端、发布订阅客户端、复制客户端配置，同样会受到maxmemory限制。
8) Redis的timeout配置可以自动关闭闲置客户端，tcp-keepalive参数可以周期性检查关闭无效TCP连接
9) monitor命令虽然好用，但是在大并发下存在输出缓冲区暴涨的可能性。
10) info clients帮助开发和运维人员找到客户端可能存在的问题。
11) 理解Redis通信原理和建立完善的监控系统对快速定位解决客户端常见问题非常有帮助


### 4.2 Java客户端 Jedis  P260

* 第三方开发包的选择
  * 选择比较稳定的版本
  * 选择更活跃的第三方开发包

* 4.2.3 Jedis连接池的使用方法

| 参数名                        | 含义                                                                                                                                                                      | 默认值                        |
| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------- |
| maxActive                     | 连接池中最大连接数                                                                                                                                                        | 8                             |
| maxIdle                       | 连接池中最大空闲的连接数                                                                                                                                                  | 8                             |
| minIdle                       | 连接池中最少空闲的连接数                                                                                                                                                  | 0                             |
| maxWaitMillis                 | 当连接池资源用尽后,调用者的最大等待时间(单位为毫秒),一般不建议使用默认值                                                                                                  | -1:表示永远都不超时, 一直等   |
| jmxEnabled                    | 是否开启jmx监控,如果应用开启了jmx端口并且jmxEnabled设置为true,就可以通过jconsole或者jvisualvm看到关于连接池的相关统计,有助于了解连接池的使用情况,并且可以针对其做监控统计 | true                          |
| minEvictableIdleTimeMillis    | 连接的最小空闲时间,达到此值后空闲连接将被移除                                                                                                                             | 1000L * 60L * 30毫秒 = 30分钟 |
| numTestsPerEvictionRun        | 做空闲连接检测时,每次的采样数                                                                                                                                             | 3                             |
| testOnBorrow                  | 向连接池借用连接时,是否做连接有效性检测(ping),无效连接会被移除,每次借用多执行一次ping命令                                                                                 | false                         |
| testOnReturn                  | 向连接池归还连接时,是否做连接有效性检测(ping),无效的连接被移除,每次归还多执行一次ping命令                                                                                 | false                         |
| testWhileIdle                 | 向连接池借用连接时,是否做连接空闲检测,空闲超时的连接会被移除                                                                                                              |
| timeBetweenEvictionRunsMillis | 空闲连接的检测周期(单位为毫秒)                                                                                                                                            | -1:表示不做检测               |
| blockWhenExhausted            | 当连接池用尽后,调用者是否要等待,与maxWaitMillis对应,只有本参数为true时, maxWaitMillis才会生效                                                                             | true                          |

* 4.2.4 Redis中Pipeline的使用方法
* 4.2.5 Jedis的Lua脚本

```java
Object eval(String script, int keyCount, String... params);
Object evalsha(String shal, int keyCount, String... params);
String scriptLoad(String script);
```

总结:
1. Jedis操作放在TryCatchFinally里更加合理
2. 区分直连和连接池两种实现方式优缺点
3. Jedis.close()方法的两种实现方式
4. Jedis依赖了common-pool, 有关common-pool的参数需要根据不同的使用场景, 各不相同
5. 如果key和value涉及了字节数组, 需要自己选择适合的序列化方法.



### 4.1 客户端通信协议

* 技术的角度看所有主流变成语言都有Redis的客户端的原因:
  * 客户端和服务器之间的通信协议是在TCP协议之上构建的
  * Redis制定了RESP(Redis Serialization rotocol, Redis序列化协议)实现客户端与服务端的正常交互, 这种协议简单高效, 既能够被机器解析, 又容易被人类识别. 


1. 发送命令格式

```shell
# CRLF 代表 "\r\n"

* <参数数量> CRLF
$<参数1的字节数量> CRLF
<参数1> CRLF
...
$<参数N的字节数量> CRLF
<参数N> CRLF
```

2. 返回结果格式

Redis的返回结果类型分为以下五种:
* 状态回复:  以 + 开头
* 错误回复:  以 - 开头
* 整数回复:  以 : 开头
* 字符串回复:  以  $  开头
* 多条字符串回复:  以  *  开头

字符串回复还是多条字符串回复, 如果有nil值, 会返回$-1

```shell
~$ nc 127.0.0.1 6379
set hello world
+OK
sethx
-ERR unknown command `sethx`, with args beginning with:
incr counter
:1
get hello
$5
world
mget java python
*2
$-1   #结果是nil
$-1
```


## 第3章 小功能大用处

### 3.9 重点回顾

1. 慢查询中的两个红药的参数 slowlog-log-slower-than 和 slowlog-max-len
2. 慢查询不包含命令网络传输和排队时间
3. 有必要将慢查询定期存放
4. redis-cli一些重要的选项, 例如 --latency, --bigkeys, -i 和 -r 组合
5. redis-benchmark的使用方法和重要参数
6. Pipeline可以有效减少RTT次数, 但每次Pipeline的命令数量不能无节制
7. Redis可以使用Lua脚本创造出原子, 高效, 自定义命令组合
8. Redis执行Lua脚本有两种方法: eval 和 evalsha
9. Bitmaps 可以用来做独立用户统计, 有效节省内存
10. Bitmaps 中 setbit 一个大的偏移量, 由于申请大量内存会导致阻塞.
11. HyperLogLog虽然在统计独立总量时存在一定的误差,但是节省的内存量十分惊人
12. Redis的发布订阅机制相比许多专业的消息队列系统功能较弱, 不具备堆积和回溯消息的能力, 但胜在足够简单
13. Redis3.2提供了GEO功能, 用来实现基于地理位置信息的应用, 但底层实现是zset






### 3.8 GEO   地理信息定位  P239

* 支持存储地理位置信息来实现 附近位置,  摇一摇 这类 依赖地理位置信息的功能

1. 添加地理位置信息   `geoadd key longitude latitude member [ longitude latitude member ... ]`
2. 获取地理位置信息   `geopos key member [ member ... ]`
3. 获取两个地理位置的距离  `geodist key member1 member2 [unit]`

* unit : m米, km公里, mi英里, ft尺

```shell
127.0.0.1:6379> geoadd gettest 116.28 39.55 beijing 117.12 39.08 tianjin 114.29 38.02 shijiazhuang 118.01 39.38 tangshan 115.29 38.51 baoding
(integer) 5
127.0.0.1:6379> geopos gettest tianjin
1) 1) "117.12000042200088501"
   2) "39.0800000535766543"
127.0.0.1:6379> geodist gettest tianjin beijing km
"89.2061"
127.0.0.1:6379> geodist gettest tianjin beijing m
"89206.0576"
127.0.0.1:6379> geodist gettest tianjin beijing ft
"292670.7926"
127.0.0.1:6379> geodist gettest tianjin beijing mi
"55.4302"
```

4. 获取指定位置范围内的地理信息位置集合  P241

`georadius key longitude latitude radiusm|km|ft|mi `
`georadiusbymember key member radiusm|km|ft|mi [ withcoord ] [ withdist ] [ withhash ] [ COUNT count ] [ asc|desc] [ store key ] [ storedist key ]`

* georadius 和 georadiusbymember 以一个地理位置为中心算出指定半径内的其他地理信息位置
* georadius命令的中心位置给出了具体的经纬度
* georadiusbymember 命令 只需要给出成员即可
* 参数
  * radiusm|km|ft|mi是必须参数 , 指定了半径(带单位)
  * withcoord  返回结果中包含经纬度
  * withdist 返回结果中包含离中心节点位置的距离
  * withhash  返回结果中包含 geohash, 有关geohash后面介绍
  * COUNT count   指定返回结果的数量
  * asc|desc   返回结果按照离中心节点的距离做升序或降序
  * store key  将返回结果的地理位置信息保存到指定键
  * storedist key   将返回结果离中心节点的距离保存到指定键

```shell
127.0.0.1:6379> GEORADIUSBYMEMBER gettest beijing 150 km
1) "beijing"
2) "tianjin"
3) "tangshan"
4) "baoding"
```

5. 获取geohash `geohash key member [ member ... ]`  将二维经纬度转为一维字符串

```shell
127.0.0.1:6379> geohash gettest beijing
1) "wx48ypbe2q0"
```

* 特点
  * GEO的数据类型为zset, Redis将所有地理位置信息的geohash存放在zset中
  * 字符串越长, 表示的位置更精确
  * 两个字符串越相似, 他们之间的距离越近, Redis利用字符串前缀匹配算法实现相关命令
  * geohash编码和经纬度是可以相互转换的

6. 删除地理位置信息 `zrem key member`



### 3.7 发布订阅  P231

* 基于"发布/订阅"模式的消息机制
* 发布者客户端向指定的 频道 channel 发布消息, 订阅该频道的每个客户端都可以收到该信息

3.7.1 命令

1. 发布消息   `publish channel message`
2. 订阅消息    `subscribe channel [ channel ... ]`

* 订阅命令有两点需要注意:
  * 客户端在执行订阅命令后 进入订阅状态,  只能接受 subscribe , psubscribe , unsubscribe , punsubscribe 四个命令
  * 新开启的订阅客户端, 无法收到该频道之前的消息, 因为Redis不会对发布的消息进行持久化

3. 取消订阅  `unsubscribe [ channel [ channel ... ] ]`
   
* 都订阅模式了, 这么输入这个?

4. 按照模式订阅和取消订阅

* `psubscribe pattern [ pattern ... ]`
* `punsubscribe [ pattern [ pattern ... ] ]`

5. 查询订阅

* 查看活跃的频道 `pubsub channels [ pattern ]`
* 查看频道订阅数 `pubsub numsub [ channel ... ]`
* 查看模式订阅数 `pubsub numpat`

3.7.2 使用场景



### 3.6 HyperLogLog  P226

* 实际类型为字符串类型, 是一种基数算法, 可以利用极小的内存空间完成独立总数的统计
* 数据集可以是 IP, Email, ID
* 占用内存极小, 但是存在错误率, 开发者在进行数据结构选型时需要确认:
  * 只为了计算独立总数, 不需要获取单条数据
  * 可以容忍一定容差率, 

1. 添加元素 `pfadd key element [ element ... ]`  成功返回1
2. 计算独立用户数 `pfcount key [ key ... ]`

* 使用内存极小, 但有0.81%的失误率, 准确率是99.19%???

3. 合并 `pfmerge destkey sourcekey [ sourcekey ]`

* destkey 最终结果集

```shell
127.0.0.1:6379> pfadd pfa unid-1 unid-2 unid-3
(integer) 1
127.0.0.1:6379> pfcount pfa
(integer) 3
127.0.0.1:6379> pfadd pfb unid-1 unid-2 unid-4 unid-5
(integer) 1
127.0.0.1:6379> pfcount pfa pfb
(integer) 5
```

### 3.5 Bitmaps

3.5.1 数据结构模型

* 本身不是一种数据结构, 是字符串, 但可以进行位操作
* 单独提供了一套命令, 所以与字符串的方法不同
* 以位为单位的数组, 单元只能存0或1, 下标叫做偏移量

3.5.2 命令

1. 设置值 `setbit key offset value`

* 第一次使用Bitmaps时, 假如偏移量非常大, 初始化过程会比较慢, 可能会造成Redis的阻塞

2. 获取值 `getbit key offset`  如果偏移量不存在, 返回的也是0
3. 获取Bitmaps指定范围值为1的个数 `bitcount [ start end ]`  start和end 必须同时存在
4. Bitmaps间的运算 `bitop op destkey key [ key ... ]`

* op : and(交集) , or(并集) , not(非) , xor(异或)
* destkey : 处理结果

5. 计算 Bitmaps 中每一个值为 targetBit 的偏移量 `bitpos key targetBit [ start  end ]`

* 这里存在疑问: 

```shell
127.0.0.1:6379> getbit bita 10
(integer) 1
127.0.0.1:6379> bitpos bita 0 1 1
(integer) 8   # 这里为什么是8
```

3.5.3 Bitmaps 分析

节约记录空间, 单也不是绝对的, 僵尸粉害死人


### 3.4 事务与Lua

3.4.1 事务

* Redis提供了简单的事务功能, 不支持事务中的回滚特性, 同时无法实现命令之间的逻辑关系计算
* 将一组需要一起执行的命令放到 multi 和 exec 两个命令之间. 
  * multi 命令代表事务开始
  * exec 命令代表事务的结束 并开始执行
  * discard 命令 停止事务的执行
* 事务中出现错误:
  * 命令错误,  属于语法错误, 整个事务无法执行, key和counter的值未发生变化
  * 运行时错误   例如使用了错误的命令, Redis不会回滚, 只能有开发人员自己修复
* watch命令,  确保在事务中的key没有被其他客户端修改过, 才执行事务, 否则不执行

3.4.2 Lua用法简述

* 详见[Lua的官方网站](http://www.Lua.org)

3.4.3 Redis与Lua

1. 在Redis中使用Lua

两种方法: eval  和   evalsha

* eval  `eval 脚本内容 key个数  key列表 参数列表`

```shell
127.0.0.1:6379> eval 'return "hello " .. KEYS[1] .. ARGV[1]' 1 redis world
"hello redisworld"
```

* redis-cli --eval 直接执行文件 

* evalsha 
  * 首先将Lua脚本加载到Redis服务端, 得到该脚本的SHA1校验和
  * 使用SHA1作为参数可以直接执行对应Lua脚本, 避免每次发送Lua脚本的开销
  * 加载脚本: script load 命令 可以将脚本内容加载到Redis内存中
  * 执行脚本:   `evalsha 脚本SHA1值 key个数 key列表 参数列表`

2. Lua的Redis API    [官网](https://redis.io/commands/eval)

可以使用 redis.call 函数实现对Redis的访问,  也可以使用会忽略错误继续执行的  redis.pcall


```shell
# lua_get.lua
return redis.call("get",KEYS[1])

----

~$ redis-cli script load "$(cat lua_get.lua)"
"f2180f334e61b6cd9beecd7eb4721473daaa9f4e"
~$ redis-cli
127.0.0.1:6379> evalsha f2180f334e61b6cd9beecd7eb4721473daaa9f4e 1 ght
"aaa"
```

* 开发提示

Lua可以使用 redis.log 函数 将Lua脚本的日志输出到 Redis的日志文件中,  单一定要控制日志级别

[Redis Lua 脚本调试器](http://redis.io/topics/ldb)

3.4.4  案例 P213

Lua脚本功能的好处:
* Lua脚本在Redis中是原子执行的, 执行过程中间不会插入其他命令
* Lua脚本可以帮助开发和运维人员创造出自己定制的命令, 并可以将这些命令常驻在Redis内存中, 实现复用的效果
* Lua脚本可以将多条命令一次性打包, 减少网络开销

Lua脚本如果使用不当, 破坏性也是难以想象!!

3.4.5 Redis如何管理Lua脚本

* script load 用于Lua脚本加载到Redis内存中
* script exists sha1 [ sha1... ]  判断sha1是否已经加载到Redis内存中
* script flush 清楚Redis内存已经加载的所有Lua脚本
* script kill  杀掉正在执行的Lua脚本. 如果Lua脚本的执行阻塞了Redis
  * Redis 提供了 lua-time-limit 参数 默认5秒.  是Lua脚本的超时时间, 但仅当Lua脚本超时后, 向其他命令调用发送 BUSY 的信号, 不会停止脚本执行. 当Lua脚本超时后, 其他客户端在执行正常命令时, 将会收到 "Busy Redis is busy running a script"错误, 并提示使用script kill或者 shutdown nosave命令杀死这个 busy 的脚本.
  * 注意: 如果Lua脚本正在执行写操作, script kill 不会生效, 会收到异常信息



### 3.3 Pipeline

3.3.1 Pipeline概念

* RTT 返回时间 Round Trip Time 包括 发送命令阶段 + 返回结果阶段
* 大量不支持批量操作的命令在现实中执行效率低
* Pipeline机制 将一组Redis命令组装, 通过一次RTT传输给Redis, 将在这组命令的执行结果按顺序返回客户端, 
* redis-cli --pipe选项使用Pipeline机制
* 大部分Redis客户端都支持Pipeline, 如 Jedis

3.3.2 性能测试

* Pipeline执行速度一班比逐条执行快
* 客户端和服务端的网络延迟越大, Pipeline效果越明显

3.3.3 原生批量命令与Pipeline对比

* 原始批量命令是原子的, Pipeline是非原子的
* 原生批量命令是一个命令对应多个key, Pipeline支持多个命令
* 原生批量命令是Redis服务端支持实现的, Pipeline需要服务端和客户端的共同实现

3.3.4 最佳实践

* 虽然好用, 单每次组装的命令个数要有节制, 否则会增加客户端的等待时间, 还会造成一定的网络阻塞
* 可将大量命令拆分多次来完成
* 只能操作一个Redis实例, 单在分布式Redis场景中, 也可以作为批量操作的重要优化手段


### 3.2 Redis Shell

* 提供了 redis-cli, redis-server, redis-benchmark等Shell工具

3.2.1 redis-cli详解

1. -r    repeat  将命令执行多次

```shell
$ redis-cli -r 3 ping
PONG
PONG
PONG
```

2. -i    interval  每隔几秒执行一次命令
   * -i 选项 必须和 -r 选项一起使用
   * 单位是秒, 不支持毫秒, 但是可以输入小数   如 -i 0.01  表示 每10毫秒

```shell
$ redis-cli -r 3 -i 1 ping
PONG
PONG
PONG

$ redis-cli -r 3 -i 0.01 ping
PONG
PONG
PONG

$ redis-cli -r 3 -i 1 info | grep used_memory_human
used_memory_human:854.80K
used_memory_human:854.97K
used_memory_human:854.97K
```

3. -x   从标准输入 stdin  读取数据作为redis-cli的最后一个参数

```shell
$ echo "world" | redis-cli -x set hello
OK
```

4. -c    cluster   连接Redis Cluster节点是需要使用的, 可以防止moved和ask异常
5. -a    auth 如果Redis设置了密码, 可以用-a选项, 不必手动输入auth命令
6. --scan 和 --pattern   扫描指定模式的键, 相当于scan命令
7. --slave   把当前客户端模拟成当前Redis节点的从节点
   * 可以用来获取当前Redis节点的更新操作
   * 合理利用, 可以记录当前连接Redis节点的一些更新操作

```shell
$ redis-cli --slave
sending REPLCONF capa eof
SYNC with master, discarding 764 bytes of bulk transfer...
SYNC done. Logging commands from master.
"PING"
"PING"
"PING"
"SELECT","0"
"set","ght","aaa"
"PING"
```

8. --rdb  请求Redis实例生成并发送RDB持久化文件, 保存在本地
   * 做持久化文件的定期备份

9. --pipe  将命令封装成Redis通信协议定义的数据格式, 批量发送给Redis执行
10. --bigkeys   使用scan命令对Redis的键进行采样, 从中找到内存占用比较大的键值, 这些键可能是系统的瓶颈
11. --eval  执行指定Lua脚本
12. --latency  检测客户端到目标Redis的网络延迟
13. --latency-history    每15秒输出一次, 可以通过-i控制间隔时间
14. --latency-dist  检测网络延迟   使用统计图表的形式
15. --stat   实时获取Redis的重要统计信息, 一些增量的数据 如 requests
16. --raw 和 --no-raw  要求命令的返回必须是原始的格式  --raw相反

```shell
~$ redis-cli set hello "你好"
OK
~$ redis-cli get hello
"\xe4\xbd\xa0\xe5\xa5\xbd"
~$ redis-cli --no-raw get hello
"\xe4\xbd\xa0\xe5\xa5\xbd"
~$ redis-cli --raw get hello
你好
```

3.2.2 redis-server详解

* 除了启动Redis外, 还有一个 --test-memory选项, 用来检测当前操作系统能否稳定地分配指定容量的内存给Redis
* 通过检测可以有效避免因为内存问题造成Redis崩溃
* --test-memory 是 简单检测, 更偏向于调试和测试, 无需每次开启Redis实例都执行

3.2.3 redis-benchmark详解

* 可以为Redis做基准性能测试

1. -c clients   代表客户端的并发数量 (默认是50)
2. -n< requests >    num   代表客户端请求总数 (默认是100000)

```shell
# 100个客户端同时请求Redis, 一共执行20000次
~$ redis-benchmark -c 100 -n 20000 get ght
====== get ght ======
  20000 requests completed in 0.82 seconds
  100 parallel clients
  3 bytes payload
  keep alive: 1
  host configuration "save": 900 1 300 10 60 10000
  host configuration "appendonly": no
  multi-thread: no

0.00% <= 1.2 milliseconds
0.01% <= 1.3 milliseconds
0.26% <= 1.4 milliseconds
1.53% <= 1.5 milliseconds
5.37% <= 1.6 milliseconds
14.61% <= 1.7 milliseconds
28.19% <= 1.8 milliseconds
42.34% <= 1.9 milliseconds
53.91% <= 2 milliseconds
97.93% <= 3 milliseconds
99.98% <= 4 milliseconds
100.00% <= 4 milliseconds
24509.80 requests per second
```

3. -q 仅仅显示redis-benchmark的requests per second信息

```shell
~$ redis-benchmark -c 100 -n 20000 -q get ght
get ght: 23837.90 requests per second
```

4. -r  随机插入更多键, 会在key, counter键上加一个12位的后缀, -r10000表示只对后四位做随机处理(-r不是随机数的个数)

`redis-benchmark -c 100 -n 20000 -r 10000`
`"key:{tag}:000000003592"`

5. -P 每个请求pipeline的数据量 (默认为1)
6. -k< boolean > 代表客户端是否使用keepalive, 1:使用(默认), 0:不使用
7. -t  可以指定命令进行基准测试

```shell
~$ redis-benchmark -t get,set -q
SET: 24630.54 requests per second
GET: 25471.22 requests per second
```

8. --csv 会将结果按照csv格式输出, 便于后续处理, 如导出到Excel等

```shell
~$ redis-benchmark -t get,set --csv
"SET","25271.67"
"GET","25793.14"
```

### 3.1 慢查询分析

* 系统在命令执行前后计算每条命令的执行时间, 当超过预设阈值, 将这条命令的相关信息(发生时间,耗时, 命令的详细信息)记录下来
* 命令的声明周期: 发布命令, 命令排队, 命令执行, 返回结果.   
* 慢查询只统计`命令执行`的时间, 所以没有慢查询并不代表客户端没有超时问题

3.1.1 慢查询的两个配置参数

* slowlog-log-slower-than 预设阈值 
  * 单位:微秒, 默认值: 10000,  10毫秒   1秒等于1000000微秒
  * 等于0, 会记录所有的命令
  * 小于0, 不会记录任何命令
* slowlog-max-len   慢查询日志列表的最大长度

* 修改配置的方法
  * 修改配置文件
  * 使用 `config set` 命令 动态修改
  * 使用 `config rewrite` 命令, 将配置持久化到本地配置文件

```shell
127.0.0.1:6379> config set slowlog-log-slower-than 100
OK
127.0.0.1:6379> config set slowlog-max-len 1000
OK
127.0.0.1:6379> config rewrite
OK
```

* 获取慢查询日志 `slowlog get [ n ]`

```shell
127.0.0.1:6379> slowlog get
1) 1) (integer) 2    # 标识ID
   2) (integer) 1602485820  # 发生时间戳
   3) (integer) 3005        # 命令耗时
   4) 1) "config"           # 执行命令
      2) "rewrite"
   5) "127.0.0.1:52061"
   6) ""
```

* 获取慢查询日志列表当前的长度 `slowlog len`

```shell
127.0.0.1:6379> slowlog len
(integer) 4
```

* 慢查询日志重置  `slowlog reset`

3.1.2 最佳实践

* 实际使用过程中要注意的几点:
  * slowlog-max-len 配置建议: 
    * 线上建议调大慢查询列表, 
    * 记录慢查询时, Redis会对长命令做截断操作, 并不会占用大量内存,
    * 增大慢查询列表可以减缓慢查询被剔除的可能, 
    * 线上可以配置1000以上
  * slowlog-log-slower-than 配置建议: 
    * 默认值超过10毫秒判定为慢查询, 需要根据Redis并发量调整该值.
    * 由于Redis采用单线程响应命令, 对于高流量场景, 每个命令执行时间在1毫秒以上, Redis最多可支撑OPS不到1000. 
    * 对于高OPS场景的Redis建议设置为1毫秒
  * 慢查询只记录命令执行时间, 并不包括命令排队和网络传输时间. 
    * 客户端执行命令的时间会大于命令实际执行时间
    * 因为命令执行排队机制, 慢查询会导致其他命令级联阻塞, 因此当客户端出现请求超时, 需要检查改时间点是否有对应的慢查询, 从而分析处是否为慢查询导致的命令级联阻塞
  * 由于慢查询日志是一个先进先出的队列
    * 慢查询比较多的情况下, 会丢失部分慢查询命令. 为了避免, 可以定期执行show get命令将慢查询日志持久化到其他存储中(Mysql), 然后制作可是话界面进行查询

---

* 慢查询分析: 通过慢查询分析, 找到有问题的命令进行优化
* Redis Shell: 功能强大的Redis Shell会有意想不到的使用功能
* Pipeline: 通过Pipeline (管道或者流水线) 机制有效提高客户端性能
* 事务 与 Lua : 制作自己的专属原子命令
* Bitmaps: 通过在字符串数据结构上使用位操作, 有效节约内存, 为开发提供新的思路
* HyperLogLog: 一种基于概率的新算法, 难以想象地节省内存空间
* 发布订阅: 基于发布订阅模式的消息通信机制
* GEO: Redis3.2提供了基于地理位置信息的功能


## 第2章 API的理解和使用 P60

### 2.8 重点回顾

1. Redis提供了5种数据结构, 每种数据结构都有多种内部编码实现
2. 纯内存存储, IO多路复用技术, 单线程架构 是Redis高性能的三个因素
3. 由于Redis的单线程架构, 所以需要每个命令能被快速执行完, 否则会造成Redis的阻塞. 理解Redis单线程命令处理机制是开发和运维Redis的核心之一
4. 批量操作(例如 mget, mset, hmset 等)能够有效提高命令执行的效率, 但要注意每次批量操作的个数和字节数
5. 了解每个命令的时间复杂度在开发中至关重要, 如 keys, hgetall, smembers, zrange等时间复杂度较高的命令是, 需要考虑数据规模对Redis的影响
6. persist命令可以删除任意类型键的过期时间, 但是 set 命令也会删除字符串类型键的过期时间, 容易被忽视
7. move, dump+restore, migrate是Redis发展过程中三种迁移键的方式, move命令基本废弃, migrate命令原子性的方式实现了dump+restore, 并且支持批量操作, 是Redis Cluster实现水平扩容的重要工具
8. scan命令可以解决keys命令可能带来的阻塞问题, 同时Redis还提供了hscan, sscan, zscan渐进式遍历hash, set, zset


### 2.7 键管理

2.7.1 单个键管理

# * 键重命名 `rename key newkey`
# * 键重命名 newkey不存在是才能成功   `renamenx key newkey`

* 使用rename时
  * 由于重命名键期间会执行del命令删除旧的键, 如果键对应的值比较大, 会存在阻塞Redis的可能性, 不容忽视!
  * 如果rename 和 renamenx 的 key 和newkey 相同,  Redis3.2以后不会报错

# * 随机返回一个键 `randomkey`
# * 键在seconds秒后过期 `expire key seconds` 
# * 键在秒级时间戳timestamp后过期  `expireat key timestamp`
# * 键在milliseconds毫秒后过期 `pexpire key milliseconds`
# * 键在毫秒级时间戳timestamp后过期 `pexpireat key milliseconds-timestamp`

无论是秒级还是毫秒级, 在Redis内部都是用的 毫秒级 pexpireat

注意: 
* 如果expire key 的键不存在, 返回结果为0
* 如果过期时间为负值, 键会立即被删除, 和del命令一样
* persist命令可以将键的过期时间清楚
* 对于字符串类型键, 执行set命令会去掉过期时间, 容易在开发中被忽视
* Redis不支持耳机数据结构 例如哈希, 列表  内部元素的过期功能, 例如不能对列表类型的一个元素做过期时间设置
* setex命令作为 set + expire 的结合, 不但是原子执行, 同时减少了一次网络通信的时间

```shell
127.0.0.1:6379> expire b 100
(integer) 1
127.0.0.1:6379> ttl b
(integer) 97
127.0.0.1:6379> get b
"1"
127.0.0.1:6379> set b 100
OK
127.0.0.1:6379> ttl b
(integer) -1
```

# * 清除键的过期时间 `persist key` 

```shell
127.0.0.1:6379> EXPIRE b 100
(integer) 1
127.0.0.1:6379> ttl b
(integer) 96
127.0.0.1:6379> persist b
(integer) 1
127.0.0.1:6379> ttl b
(integer) -1
```

# * ttl 查询键的剩余时间 秒级
# * pttl 查询键的剩余时间 毫秒级

#### 迁移键

| 命令         | 作用域   | 原子性 | 支持多个键 |
| ------------ | -------- | ------ | ---------- |
| move         | 实例内部 | 是     | 否         |
| dump+restore | 实例之间 | 否     | 否         |
| migrate      | 实例之间 | 是     | 是         |


# * 在Redis内部进行数据迁移 `move key db` 
# * dump + restore 实现在不同的Redis实例之间进行数据迁移

* `dump key` 在源Redis上, 将键值序列化, 格式采用的是RDB格式
* `restore key ttl value` 在目标Redis上, 将上面序列化的值进行复原, 其中ttl参数代表过期时间, 如果 ttl=0代表没有过期时间
* 注意:
  * 整个迁移过程并非原子性的, 而是通过客户端分步完成的
  * 迁移过程是开启了两个客户端连接

# * `migrate host port key|"" destination-db timeout [copy] [replace] [keys key [ key... ]]`

* Redis实例间进行数据迁移的
* 实际上是 dump restore del 三个命令进行组合
* 具有原子性, 而且从3.0.6版本以后, 支持迁移多个键, 有效的提高了迁移效率
* 与 dump + restore 的区别
  * 整个过程是原子执行的, 不需要在多个Redis实例上开启客户端, 只需要在源Redis上执行即可
  * migrate命令的数据传输直接在源Redis和目标Redis上完成的
  * 目标Redis完成restore后会发送OK给源Redis, 源Redis接收后会根据migrate对应选项来决定是否在源Redis上传出对应的键
* 参数说明:
  * host: 目标Redis的IP地址
  * port: 目标Redis的端口
  * key|"" 3.0.6之前只支持迁移一个键. 3.0.6以后可以迁移多个键, 这里是空字符串
  * destination-db: 目标Redis的数据库索引, 
  * timeout: 迁移的超时时间(单位: 毫秒)
  * [ copy ] : 如果添加此选项, 迁移后不删除源键
  * [ replace ] : 如果添加此选项, migrate不管目标Redis是否存在该键都会正常迁移进行数据覆盖, 不加遇到相同的会收到错误提示
  * [keys key [ key ... ]] : 迁移多个键, 


2.7.2 遍历建 P160

# * 全量遍历建 `keys pattern` 

* pattern 使用 glob 风格的通配符:
  * *匹配任意字符
  * .匹配一个字符
  * []匹配部分字符, 例: [ 1,3 ] 匹配 1,3   [ 1-10 ] 匹配 1到10任意数字
  * \x 用来做转义,  例如星号, 问号需要进行转义
* 例子: 
  * [ j,k ]edis   jedis kedis
* Redis的单线程架构, 如果包含大量键, keys命令会造成Redis阻塞, 不建议生产环境下使用. 万不得已可以在一下三中情况下使用
  * 在一个不对外提供服务的Redis从节点上执行, 这样不会苏泽到客户端的请求, 但会影响到主从复制
  * 如果确认键值总数确实比较少
  * 使用 scan 命令 渐进式的遍历所有键, 有效防止阻塞

# * 渐进式遍历 `scan cursor [ MATCH pattern ] [ count number ]` O(1)

* 问题: 如果执行过程中, 键发生了变化(新增,删除,修改)
  * 新增的键可能没有遍历到, 遍历出重复的键, 即不能保证遍历出所有的键
* 参数:
  * cursor 必须, 一个游标, 第一次遍历从0开始, 每次scan遍历完都会返回当前游标的值, 直到游标值为0, 表示遍历结束
  * match pattern 可选, 做模式匹配
  * count number 可选, 每次遍历的键个数, 默认10

```shell
127.0.0.1:6379> keys *
 1) "b"
 2) "mylist"
 3) "listkey"
 4) "hashAa"
 5) "user:ranking2"
 6) "myset1-2"
 7) "myset2"
 8) "user:ranking1-2"
 9) "hello"
10) "myset"
11) "d"
12) "user:ranking"
13) "c"
14) "incrTest"
127.0.0.1:6379> scan 0 count 5
1) "14"    # 下次 cursor 的值
2) 1) "b"
   2) "mylist"
   3) "user:ranking1-2"
   4) "hello"
   5) "user:ranking2"
127.0.0.1:6379> scan 14 count 5
1) "3"
2) 1) "c"
   2) "listkey"
   3) "hashAa"
   4) "d"
   5) "user:ranking"
127.0.0.1:6379> scan 3 count 5
1) "0"    # 0表示遍历结束
2) 1) "myset"
   2) "myset1-2"
   3) "myset2"
   4) "incrTest"
```

# * 遍历哈希类型的内部键     hgetall -> hscan
# * 遍历集合类型的内部键     smembers -> sscan
# * 遍历有序集合类型的内部键  zrange -> zscan


2.7.3  数据库管理

# * 切换数据库 `select dbIndex`

* 一个实例下有多个数据库存在
* 用数字作为多个数据库名
* Redis默认配置中有16个数据库, 从0开始

```shell
127.0.0.1:6379> select 1
OK
127.0.0.1:6379[1]> select
(error) ERR wrong number of arguments for 'select' command
127.0.0.1:6379[1]> select 0
OK
```

* Redis3.0中逐渐弱化了这个功能, 分布式实现Redis Cluster只允许使用0号数据库, 
* 废掉这个功能的原因
  * Redis是单线程的, 使用多个数据库时, 仍然使用一个CPU, 彼此之间还是会受到影响
  * 多数据库的使用方式, 会让调试和运维不同业务的数据库变得困难. 一个慢查询的存在会影响到其他数据库, 使得定位问题非常困难
  * 部分Redis的客户端根本就不支持这种方式. 即使支持, 在开发的时候来回切换数字形式的数据库, 容易混乱
* 如果要使用多个数据库功能, 完全可以在一台机器上部署多个Redis实例, 彼此用端口来区分, 彼此之间业务不会受到影响,还可以充分利用CPU资源

# * 清除当前数据库  `flushdb`
# * 清除全部数据库   `flushall`

* 问题:
  * flushdb/flushall 命令清除所有数据, 一旦误操作后果不堪设想
  * 如果键值数量比较多, 有阻塞Redis的可能
* 一定要谨慎使用



-----

| 数据结构 | 是否允许重复元素 | 是否有序 | 有序实现方式 | 应用场景           |
| -------- | ---------------- | -------- | ------------ | ------------------ |
| 列表     | 是               | 是       | 索引下标     | 时间轴, 消息队列等 |
| 集合     | 否               | 否       | 无           | 标签, 社交等       |
| 有序集合 | 否               | 是       | 分值         | 排行榜系统, 社交等 |




### 2.6 有序集合

* 不能有重复成员, 可排序
* 不是下标排序, 而是每个元素设置一个分数score, 作为排序依据
* 成员不能重复, 但是分数可以重复

2.6.1 命令

1. 集合内 P134

# * 添加成员 `zadd key [NX|XX] [CH] [INCR] score member [score member ...]`     O(k * log(n)), k是添加成员的个数, n是当前有序集合的成员个数

* NX: member必须不存在, 才可以设置成功, 用于添加
* XX: member必须存在, 才能设置成功, 用于更新
* CH: 返回此次操作后, 有序集合元素和分数发生变化的个数
* INCR: 对score做增加, 相当于 zincrby
* 有序集合比集合提供了排序字段, 也产生了代价, zadd时间复杂度为O(log(n))   sadd时间复杂度为O(1)
  
# * 计算成员个数 `zcard key`     O(1)
# * 计算某个成员的分数 `zscore key member`  不存在返回nil    O(1)
# * 计算成员的排名 `zrank key member`   从低到高排名     第一名是0   O(log(n)), n是当前有序集合成员个数
# * 计算成员的排名 `zrevrank key member`   从高到底排名              O(log(n)), n是当前有序集合成员个数
# * 删除成员 `zrem key member [member ...]`                       O(k * log(n)), k是删除成员的个数, n是当前有序集合的成员个数
# * 添加成员的分数 `zincrby key increment member`                 O(log(n)), n是当前有序集合成员个数

* 例子: 给tom加9分, `zincrby user:ranking 9 tom`

# * 返回指定排名范围的成员 `zrange key start stop [withscores]`   从低到高    O(k + log(n)), k是获取成员的个数, n是当前有序集合的成员个数
# * 返回指定排名范围的成员 `zrevrange key start stop [withscores]` 从高到底   O(k + log(n)), k是获取成员的个数, n是当前有序集合的成员个数

* withscores 选项: 同时返回分数值

# * 返回指定分数范围的成员 `zrangebyscore key min max [withscores] [limit offset count]`   从低到高   O(k + log(n)), k是获取成员的个数, n是当前有序集合的成员个数
# * 返回指定分数范围的成员 `zrevrangebyscore key max min [withscores] [limit offset count]` 从高到低   O(k + log(n)), k是获取成员的个数, n是当前有序集合的成员个数

* limit offset count : 限制输出的起始位置和个数
* min 和 max 支持 开区间 (小括号) ~~和闭区间 [ 中括号 ]~~,  -inf和+inf 代表无限小和无限大
  * 例子 
    * (200 +inf  => 200 ＜ x ≤ ∞      
    * (200 (300  => 200 ＜ x ＜ 300   
    * 200 300 =>  200 ≤ x ≤ 300

# * 返回指定分数范围成员个数 `zcount key min max`                O(log(n)), n是当前有序集合成员个数
# * 删除指定排名内的升序成员 `zremrangebyrank key start stop`    O(k + log(n)), k是删除成员的个数, n是当前有序集合的成员个数
# * 删除指定分数范围的成员 `zremrangebyscore key min max`        O(k + log(n)), k是删除成员的个数, n是当前有序集合的成员个数

2. 集合间的操作

# * 交集 `zinterstore destination numkeys key [key ...] [weights weight [weight ...]] [aggregate sum|min|max]`    O(n*k)+O(m*log(m)), n成员数最小的有序集合成员个数, k是有序集合的个数, m是结果集中成员的个数

* destination: 交集计算结果保存到键
* numkeys: 需要做交集计算键的个数
* key[ key ... ]: 需要做交集计算的键
* weights weight [ weight ... ]: 每个键的权重, 在做交集计算时, 每个键中的每个member将会自己分数乘以这个权重, 每个键的权重默认是1
* aggregate sum|min|max: 计算成员交集后, 分值可以按照sum(和) , min 最小值, max 最大值做汇总, 默认是sum

```shell
127.0.0.1:6379> ZINTERSTORE user:ranking1-2 2 user:ranking user:ranking2
(integer) 1
127.0.0.1:6379> ZRANGE user:ranking1-2 0 -1 withscores
1) "ght"
2) "200"
127.0.0.1:6379> ZINTERSTORE user:ranking1-2 2 user:ranking user:ranking2 weights 1 0.5
(integer) 1
127.0.0.1:6379> ZRANGE user:ranking1-2 0 -1 withscores
1) "ght"
2) "150"
127.0.0.1:6379> ZINTERSTORE user:ranking1-2 2 user:ranking user:ranking2 weights 1 0.5 aggregate max
(integer) 1
127.0.0.1:6379> ZRANGE user:ranking1-2 0 -1 withscores
1) "ght"
2) "100"
127.0.0.1:6379> ZINTERSTORE user:ranking1-2 1 user:ranking user:ranking2 weights 1 0.5 aggregate max
(error) ERR syntax error
127.0.0.1:6379> ZINTERSTORE user:ranking1-2 3 user:ranking user:ranking2 weights 1 0.5 aggregate max
(error) ERR syntax error
```

# * 并集 `zunionstore destination numkeys key [key ...] [weights weight [weight ...]] [aggregate sum|min|max]`  O(n)+O(m*log(m)), n是所有有序集合成员个数和, m是结果集中成员个数

```shell
127.0.0.1:6379> ZunionSTORE user:ranking1-2 2 user:ranking user:ranking2 weights 1 0.5 aggregate max
(integer) 9
127.0.0.1:6379> ZRANGE user:ranking1-2 0 -1 withscores
 1) "jw"
 2) "11.5"
 3) "wg"
 4) "12"
 5) "zrh"
 6) "15"
 7) "mx"
 8) "22"
 9) "tj"
10) "22"
11) "ld"
12) "27.5"
13) "xcr"
14) "34"
15) "whk"
16) "49.5"
17) "ght"
18) "100"
```

2.6.2 内部编码

* ziplist 压缩列表: 当有序集合的元素个数小于 zset-max-ziplist-entries配置(默认128个), 同时每个元素的值都小于zset-max-ziplist-value配置(默认64字节),  有效减少内存的使用
* skiplist 跳跃表: 

2.6.3 使用场景

* 排行榜系统


### 2.5 集合

* 用来保存多个字符串元素, 不允许有重复元素, 并且集合中的元素是无序的, 不能通过索引下标获取元素
* 一个集合最多有2^32-1个元素(4,294,967,295). 
* Redis支持 对集合内的增删改查, 多个集合取交, 并, 差集

2.5.1 命令

1. 集合内操作  P124

# * 添加元素 `sadd key element [element ...]`   O(k)  k是元素个数
# * 删除元素 `srem key element [element ...]`   O(k)  k是元素个数
# * 计算元素个数 `scard key`                     O(1)
# * 判断元素是否在集合中 `sismember key element`    O(1)
# * 随机从集合返回指定个数元素 `srandmember key [count]`    O(count)
# * 从集合随机弹出元素 `spop key [count]` 执行后元素会被删除    O(1)
# * 获取所有元素 `smembers key`                             O(n)  n是元素总数

* smembers , lrange , hgetall 属于比较重的命令, 元素过多存在阻塞Redis的可能, 建议使用 sscan

2. 集合间操作

# * 求多个集合的交集 `sinter key [key ...]`              O(m*k) k是多个集合中元素最少的个数, m是键个数
# * 求多个集合的并集 `sunion key [key ...]`              O(k)   k是多个集合元素个数和
# * 求多个集合的差集 `sdiff key [key ...]`  集合的顺序不同, 结果不同     O(k)   k是多个集合元素个数和
# * 交集结果保存 `sinterstore destination key [key ...]`   O(m*k) k是多个集合中元素最少的个数, m是键个数
# * 交集结果保存 `sunionstore destination key [key ...]`   O(k)   k是多个集合元素个数和
# * 交集结果保存 `sdiffstore destination key [key ...]`    O(k)   k是多个集合元素个数和

* destination 处理储存到的key

2.5.2 内部编码

* intset (整数集合) : 当集合中的元素都是整数且元素个数小于 set-max-intset-entries 配置(默认 512个)时 , 减少内存的使用
* hashtable (哈希表) : 

2.5.3 使用场景

* sadd = Tagging 标签
  * 用户和标签的关系维护应该在一个事务内执行, 防止部分命令失败造成的数据不一致   Redis的事务!!
* spop / srandmember = Random item (生成随机数, 比如抽奖)
* sadd + sinter = Social Graph (社交需求)

### 2.4 列表

* 用来存储多个有序的字符串,  每个字符串就是一个元素(element), 一个列表最多 2^32-1个元素 (4,294,967,295). 
* 可以从列表的两端插入(push)和弹出(pop), 可以获取指定范围的元素列表, 获取指定索引下标的元素
* 可以当栈 和 队列 的角色
* 列表类型的特点: 
  * 第一, 列表中的元素是有序的, 通过索引下标获取某个元素或者某个范围内的元素列表
  * 第二, 列表中的元素是可以重复的

2.4.1 命令

| 操作类型 | 操作                 |
| -------- | -------------------- |
| 添加     | rpush lpush linsert  |
| 查       | lrange lindex llen   |
| 删除     | lpop rpop lrem ltrim |
| 修改     | lset                 |
| 阻塞操作 | blpop brpop          |

1. 添加操作

# * 从右边插入元素 `rpush key value [value...]`  O(k) k是元素个数
# * 从左边插入元素 `lpush key value [value...]`  O(k) k是元素个数
# * 向某个元素前或后插入元素 `linsert key before|after pivot value`   O(n) n是pivot距离列表头或尾的距离

* 找到等于pivot的元素, 在其前(before)或后(after)插入一个新的元素value
* `linsert listkey after b w`  

2. 查找

# * 从左到右获取列表所有元素 `lrange key start end`   O(s+n) s是start偏移量, n是start到end的范围

* 索引的两个特点:
  * 从左到右分别是  0  到  N-1,  从右到左分别是   -1   到  -N
  * lrange中的end 包含了自身
* `lrange listkey 0 -1`

# * 获取列表指定索引下标的元素 `lindex key index`   O(n) , n是索引的偏移量
# * 获取列表长度 `llen key`     O(1)

3. 删除

# * 从列表左侧弹出元素 `lpop key`      O(1)
# * 从列表右侧弹出元素 `rpop key`      O(1)
# * 删除指定元素 `lrem key count value`   O(n) , n是列表长度

* count的三种情况
  * count > 0 从左到右 , 删除最多count个元素
  * count < 0 从右到左 , 删错最多count绝对值个元素
  * count = 0 删除所有

# * 按照索引范围修剪列表 `ltrim key start end`    O(n) , n是要裁剪的元素总数

4. 修改

# * 修改指定索引下标的元素 `lset key index newValue`   O(n) , n是索引的偏移量

5. 阻塞操作 这个阻塞, 只是IO的阻塞, 并不会影响到Redis的运行,

# * 阻塞式弹出 左 `blpop key [key ...] timeout`    O(1)
# * 阻塞式弹出 右 `brpop key [key ...] timeout`    O(1)

* key[key ...] : 多个列表的键
* timeout : 阻塞时间(单位: 秒)
  * 列表为空: 如果timeout = 3 , 那么客户端要等到3秒后返回, 如果timeout = 0, 那么客户端会一直阻塞等下去, 直到有新的元素添加到列表中
  * 列表不为空: 客户端会立即返回
* 注意: 
  * 如果是多个键, brpop会从左至右遍历键, 一旦有一个键能弹出元素, 客户端立即返回. 也就是说, 从这些列表中弹出一个出来. 
  * 如果多个客户端对同一个键执行brpop, 那么最先执行brpop命令的客户端获取到弹出的值

2.4.2 内部编码

* ziplist(压缩列表)
  * 当列表的元素个数小于 list-max-ziplist-entries配置(默认512个), 同时列表中每个元素的值都小于list-max-ziplist-value配置时(默认64字节)
  * 减少内存的使用
* linkedlist(链表): 当列表类型无法满足ziplist的条件时
* quicklist : 以ziplist为节点的linkedlist, 结合了ziplist和linkedlist两者的优势, 为列表类型提供了一个更为优秀的内部编码实现

2.4.3 使用场景

1. 队列消息

* lpush + brpop 命令组合, 实现阻塞队列
* 生产者用lpush 插入元素
* 消费者用 brpop 抢夺元素, 谁抢到了谁干活,  保证了消费的负载均衡和高可用性

2. 文章列表

口诀:
* lpush + lpop = Stack 栈
* lpush + rpop = Queue 队列
* lpush + ltrim = Capped Collection 有限集合
* lpush + brpop = Message Queue 消息队列



### 2.3 哈希

* 键值本身又是一个键值对结构

2.3.1 命令

# * 设置值 `hset key field value [ field value ... ]` 成功返回1   O(k) k是field个数
# * 设置值, 当field不存在的时候才插入 `hsetnx key field value`     O(1)
# * 获取值 `hget key field`   如果field不存在, 返回nil            O(1) 
# * 删除field `hdel key field [ field ... ]`                      O(k) k是field个数
# * 计算field个数 `hlen key`                                      O(1)
# * 批量设置field-value  `hmset key field value [ field value ... ]`    O(k) k是field个数
# * 批量获取field-value  `hmget key field [ field ... ]`                O(k) k是field个数
# * 判断field是否存在 `hexists key field`   存在返回1               O(1)
# * 获取所有field  `hkeys key`                   O(n) n是field总数
# * 获取所有value  `hvals key`                   O(n) n是field总数
# * 获取所有的field-value  `hgetall key` 得到的是一个field 一个value 的列表, 不是一个map     O(n) n是field总数

在使用hgetall时, 如果哈希元素个数比较多, 会存在阻塞Redis的可能, 如果开发人员只需要获取部分field, 可以使用 hmget , 如果一定要获取全部 field-value , 可以使用 hscan命令, 这个命令会渐进式遍历哈希类型

# * 自增指定数字 `hincrby key field increment`                      O(1)
# * 自增指定浮点数字  `hincrbyfloat key field increment`             O(1)
# * 计算value的字符串长度 `hstrlen key field`              O(1)

2.3.2 内部编码 P(100)

* ziplist (压缩列表) : 当元素个数小于 hash-max-ziplist-entries配置(默认512个), 同时所有值都小于hash-max-ziplist-value配置(默认64字节)是
  * 更加紧凑结构实现多个元素的连续存储, 在节约内存方面比hashtable更加优秀
* hashtable (哈希表) : 当不满足ziplist条件时, hashtable的读写时间复杂度为O(1), 

2.3.3 使用场景 P(102)

存储关系型数据

哈希类型和关系型数据库的不同点:
1. 哈希类型是稀疏的, 关系型数据库是完全结构化的.  哈希的field不一定存在, 关系型数据库的字段会是null
2. 关系型数据库可以做复杂的关系查询, 而Redis模拟复杂关系查询, 开发困难和维护成本高


三种缓存用户信息的方法:

1. 原生字符串类型, 每个属性一个键  `set user:1:name tom user:1:age 23`
   * 优点: 简单直观, 每个属性都可支持更新操作
   * 缺点: 占用过多的键, 内存占用量较大, 同时用户信息内聚性比较差, 一般不会在生产环境使用
2. 序列化字符串类型: 将用户信息序列化后用一个键保存
   * 优点: 简化变成, 如果合理的使用序列化可以提高内存的使用效率
   * 缺点: 序列化和反序列化有一定的开销, 用时每次更新属性都需要吧全部数据取出进行反序列化, 更新后在序列化到Reids中
3. 哈希类型: 每个用户属性使用一对 field-value,  但是只用一个键保存  `hmset user:1 name tom age 23 city beijing`
   * 优点: 简单直观, 如果使用合理可以减少内存空间的使用
   * 缺点: 要控制哈希在ziplist和hashtable两种内部编码的转换, hashtable会消耗更多内存




### 2.2 字符串

* 最基础的数据结构
* 字符串类型的值可以是: 字符串, 数字, 二进制, 但值最大不能超过512MB

2.2.1 命令  

1. 常用命令

# * 设置值 `set key value [ex seconds] [px milliseconds] [nx|xx]`  O(1)   
# * 设置有秒级过期时间的值 `setex key seconds value`    O(1)   
# * 设置值且键必须不存在 `setnx key value`   O(1)   

* ex 为键设置秒级过期时间
* px 为键设置毫秒级过期时间
* nx 键必须不存在, 才能设置成功 用于添加   分布式锁
* xx 键必须存在, 用于更新


```shell
# set key value
set hello world
# 添加秒级过期时间
set hello world ex 10
# 只添加
set hello world nx
# 只更新
set hello world xx

# 添加秒级过期时间2
setex hello 10 world
# 添加一个键且键必须不存在
setnx hello world
```

# * 获取值 `get key`  键不存在返回`nil`   O(1)   

# * 批量设置值 `mset key value [key value ...]`    O(K), k是键的个数
# * 批量获取值 `mget key [key ...]`  键不存在返回`nil`    O(K), k是键的个数

批量操作是为了提高开发效率, Redis自身速度超群, 网络速度成为瓶颈, 批量处理有助于提高业务效率

# * 计数 `incr key`     O(1)

返回结果: 
* 值不是整数, 返回错误
* 值是整数, 返回自增后的结果
* 键不存在, 按照值为0自增, 返回结果为1

# * 自减 `decr key`         O(1)
# * 自增指定数字 `incrby key increment`      O(1)
# * 自减指定数字 `decrby key decrement`       O(1)
# * 自增浮点数 `incrbyfloat key increment`   O(1)

2. 不常用命令

# * 追加值 `append key value` 向字符串尾部追加值      O(1)
# * 字符串长度 `strlen key`  中文占用3个字节              O(1)
# * 设置并返回原值 `getset key value` 设置的同时, 返回原有的值           O(1)
# * 设置指定位置的字符 `setrange key offeset value`                O(1)
# * 获取部分字符串 `getrange key start end`  end是偏移量 从0开始       O(n) n是字符串长度 如果字符串长度短,约等于O(1)

2.2.2 内部编码

字符串类型有三种内部编码:

* int  8个字节的长整型
* embstr   小于等于39个字节的字符串
* ram    大于39个字节的字符串

2.2.3 典型使用场景

1. 缓存功能

# 开发提示
* Redis没有命名空间, 对键名没有强制要求,特殊字符除外
* 设计合理的键名, 有利于防止间冲突和项目的可维护性
* 推荐: 业务名:对象名:id:[ 属性 ] , 键名过长会浪费内存
  * 例子: wxzj:user:1:name   简化后可以是 wxzj:u:1:n 尽量简洁就好

2. 计数

真实的技术系统还需要考虑: 防作弊, 按照不同维度计数, 数据持久化到底层数据源等

3. 共享Session

一次登录, 多台服务器都可以正常访问

4. 限速

多台服务器共享 使用频率


### 2.1.3 单线程架构

* 单线程架构和I/O多路复用模型来实现高性能的内存数据库服务
* 单线程架构:
  * 命令先进入队列, 再逐个被执行, 执行顺序不确定, 但肯定不会有两条命令被同时执行
  * 为啥这么快? 
    * 纯内存访问 重要基础
    * 非阻塞I/O, 使用epoll作为I/O多路复用技术的实现, 事件处理模型将epoll中的连接,读写,关闭都转换为时间, 不在网络I/O上浪费时间
    * 避免了线程切换和竞态产生的消耗
  * 优势: 
    * 简化数据结构和算法的实现
    * 避免了线程切换和竞态长生的消耗, 锁和线程切换通常是性能杀手
  * 问题:
    * 某个命令执行过长, 将导致其他命令阻塞

### 2.1.2 数据结构和内部编码

* 5种对外的数据结构: 字符串(string), hash, list, set, zset
* 每个对外数据结构, 都对应着多个内部编码, 而一些内部编码也可能对应着多个对外数据结构
* Redis会在合适的场景选择合适的内部编码

| key | 数据结构 | 内部编码   |
| --- | -------- | ---------- |
| key | string   | raw        |
|     |          | int        |
|     |          | embstr     |
|     | hash     | hashtable  |
|     |          | ziplist    |
|     | list     | linkedlist |
|     |          | ziplist    |
|     | set      | hashtable  |
|     |          | intset     |
|     | zset     | skiplist   |
|     |          | ziplist    |

好处:  
1. 可以改进内部编码, 对外的数据结构和命令没有影响, 类似接口和实现类的关系
2. 多种内部编码实现可以在不同场景下发挥各自的优势

# * 查询内部编码 `object encoding key` 

### 2.1.1 全局命令

# * 查看所有键  `keys *`  会遍历所有键, 当保存大量键时, 线上环境禁止使用
# * 键总数 `dbsize`  不会遍历所有键
# * 检查键是否存在 `exists key` 1存在, 0不存在
# * 删除键 `del key [key ...]`  返回删除键的个数     O(k), k是键的个数
# * 键过期 `expire key seconds`  
# * 键剩余时间  `ttl key` 大于等于0:键剩余的过期时间,  -1:键没有设置过期时间,  -2:键不存在
# * 键的数据结构类型 `type key`  键不存在,返回none



## 第1章 初始Redis

### 1.7 重点回顾

1. Redis的8个特性: 速度快, 基于键值对的数据结构服务器, 功能丰富, 简单稳定, 客户端语言多, 持久化, 主从复制, 支持高可用和分布式
2. Redis不是万金油, 有些场景不适合
3. 开发运维结合以及阅读源码是用好Redis的重要方法
4. 生产环境中使用配置文件启动Redis
5. 生产环境选取稳定版本的Redis
6. Redis3.0是重要的里程碑, 发布了Redis官方的分布式实现Redis Cluster

### 1.6 Redis 重大版本 P53

* 版本号命名规则: 第二位如果奇数, 为非稳定版本; 偶数, 为稳定版本

1. Redis2.6 2012
2. 

### 1.4  用好Redis的建议

1. 切勿当做黑盒使用, 开发与运维同样重要,   要知道Redis的原理
2. 阅读源码

### 1.5 正确安装并启动Redis

1.5.1 安装Redis

1. 在Linux上安装Redis

```shell
# 安装gcc
$ sudo apt-get update
$ sudo apt-get install build-essential


$ wget http://download.redis.io/releases/redis-3.0.7.tar.gz
$ tar xzf redis-3.0.7.tar.gz
$ ln -s redis-3.0.7 redis
$ cd redis
$ make
$ make install
```


1) 下载Redis指定版本的源码压缩包到当前目录
2) 解压缩Redis源码压缩包
3) 建立一个redis目录的软连接, 指向 redis-3.0.7
   * 注意: 建立软连接的目的是为了不把Redis目录固定在指定版本上, 有利于Redis未来版本升级
4) 进入redis目录
5) 编译 (编译之前确保操作系统已经安装gcc)
6) 安装
   * 将Redis的相关运行文件放到 /usr/local/bin/ 下, 以便在任何目录下执行Redis命令

1.5.2 配置, 启动, 操作, 关闭Redis

* Redis Shell :  src 和 /usr/local/bin 目录下几个以redis开头的可执行文件

| 可执行文件       | 作用                               |
| ---------------- | ---------------------------------- |
| redis-server     | 启动redis                          |
| redis-cli        | Redis命令行客户端                  |
| redis-benchmark  | Redis基准测试工具                  |
| redis-check-aof  | Redis AOF 持久化文件检测和修复工具 |
| redis-check-dump | Redis RDB 持久化文件检测和修复工具 |
| redis-sentinel   | 启动 Redis Sentinel                |

1. 启动Redis

三种启动方法: 默认配置, 运行配置, 配置文件启动

1) 默认配置

* 使用 Redis 的默认配置来启动  redis-server 
* 关闭的时候报错, 无法关闭, 直接kill掉了

```
10232:M 15 Sep 2020 11:33:03.807 # User requested shutdown...
10232:M 15 Sep 2020 11:33:03.808 * Saving the final RDB snapshot before exiting.
10232:M 15 Sep 2020 11:33:03.809 # Failed opening the RDB file dump.rdb (in server root dir /usr/local/bin) for saving: Permission denied
10232:M 15 Sep 2020 11:33:03.809 # Error trying to save the DB, can't exit.
```

2) 运行启动

* redis-server 加上要修改配置名和值(可以是多对), 没有配置将使用默认

```
# redis-server --configKey1 configValue1 --configKey2 configValue2
$ redis-server --port 6380
```

3) 配置文件启动

将配置写到指定文件里

```
# redis-server /opt/redis/redis.conf
```

Redis有60多个配置, 详见第14章

| 配置名    | 配置说明                                |
| --------- | --------------------------------------- |
| port      | 端口                                    |
| logfile   | 日志文件                                |
| dir       | Redis工作目录(存放持久化文件和日志文件) |
| daemonize | 是否以守护进程的方式启动Redis           |

2. Redis命令行客户端

redis-cli有两种方式连接Redis服务器

* 第一种 交互式方式 : redis-cli -h{host} -p{port}
* 第二种 命令方式:  redis-cli -ip{host} -p{port} {command}
* 注意:
  * -h参数 默认连接 127.0.0.1
  * -p参数 默认端口 6379
  * redis-cli是Redis重要工具, 还提供了很多有价值的参数

3. 停止Redis服务

shutdown

* 注意:
  * Redis关闭的过程: 断开与客户端的连接, 持久化文件生成, 是一种相对优雅的关闭方式
  * 除了shutdown命令关闭以外, kill进程也可以关掉Redis, 但不要kill-9强制杀死, 不会做持久化操作, 还会造成缓冲区等资源不能优雅关闭, 极端情况会造成AOF和复制丢失数据的情况
  * shutdown 的参数 , 代表是否在关闭Redis前, 生成持久化文件
    * shutdown nosave|save

```
localhost:6379> SHUTDOWN
not connected>

# log
25:M 15 Sep 2020 18:01:24.176 # User requested shutdown...
25:M 15 Sep 2020 18:01:24.176 * Saving the final RDB snapshot before exiting.
25:M 15 Sep 2020 18:01:24.179 * DB saved on disk
25:M 15 Sep 2020 18:01:24.179 * Removing the pid file.
25:M 15 Sep 2020 18:01:24.180 # Redis is now ready to exit, bye bye...
```



### 1.3 Redis使用场景

#### 可以

1. 缓存  提高访问速度, 降低后端数据源的压力. 键过期时间设置, 灵活控制最大内存和内存溢出后的淘汰策略
2. 排行榜���统 列表和有序集合数据结构
3. 计数器引用 支持技术功能且技术性能非常好
4. 社交网络 
5. 消息队列系统 发布订阅功能和阻塞队列的功能, 满足基本功能

#### 不可以

* 数据规模的角度 不适合存储大规模数据
* 数据冷热的角度  不适合存储冷数据


完事开头难
---------------------

* 基于键值对的NoSQL数据库
* 值可以是 String 字符串, hash 哈希, list 列表, set 集合, zset 有序集合, Bitmaps 位图, HyperLogLog , GEO 地理信息定位 等多种数据结构和算法组成
* 所有数据在内存中, 读写性能惊人
* 利用快照和日志的形式保存到硬盘上
* 提供了 键过期, 发布订阅, 事务, 流水线, Lua脚本 等附加功能

### 1.2 Redis特性

1. 速度快
   * 所有数据都存在内存中
   * 用C语言实现
   * 单线程架构
   * 开发者的精雕细琢
2. 基于键值对的数据结构服务器, 值可以有多种类型
3. 丰富的功能
   * 键过期, 实现缓存
   * 发布订阅功能, 实现消息系统
   * 支持Lua脚本功能, 利用Lua创造出新的Redis命令
   * 简单的事务功能, 一定程度上保证事务特性
   * 流水线功能, 将一批命令一次性传到Redis, 减少网络开销
4. 简单稳定
   * 源码少
   * 单线程模型
   * 不依赖操作系统的类库, 自己实现了事件处理的相关功能
5. 客户端语言多
   * TCP通信协议, 
6. 持久化
   * 两种持久化方法:  RDB 和 AOF
7. 主从复制   复制功能, 分布式Redis的基础
8. 高可用和分布式
   * 2.8版本提供了 Redis Sentinel. 保证Redis节点的故障发现和故障自动转移. 
   * 3.0版本提供了 分布式实现Redis Cluster, 是Redis真正的分布式实现, 提供了高可用, 读写和容量的扩展性